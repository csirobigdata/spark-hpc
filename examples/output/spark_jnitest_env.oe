Begin PBS Prologue Wed Aug 27 12:04:53 EST 2014 1409105093
Job ID:              8432301.bragg-l-mgt.cluster
Username:            szu004
Group:               gpu-users
Name:                spark_jnitest_env
Resources:           neednodes=n050:ppn=2,nodes=2:ppn=1,vmem=6gb,walltime=00:00:30
Queue:               NORMAL
Nodes:               n050
First Node:          n050
Loading spark from: /home/szu004/.spark-hpc/load_spark.sh
JAVA_HOME: /apps/jdk/1.6.0_26
SPARK_HOME: /home/szu004/apps/spark/1.0.2
JAVA_HOME: /apps/jdk/1.6.0_26
SPARK_HOME: /home/szu004/apps/spark/1.0.2
Warning: SPARK_MEM is deprecated, please use a more specific config option
(e.g., spark.executor.memory or SPARK_DRIVER_MEMORY).

Spark assembly has been built with Hive, including Datanucleus jars on classpath
Picked up _JAVA_OPTIONS: -XX:ParallelGCThreads=1
14/08/27 12:04:56 INFO SparkConf: Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
14/08/27 12:04:56 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
14/08/27 12:04:56 WARN SparkConf: 
SPARK_JAVA_OPTS was detected (set to '-Dspark.hpc.test=value -Dspark.local.dir=/scr/8432301').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
14/08/27 12:04:56 WARN SparkConf: Setting 'spark.executor.extraJavaOptions' to '-Dspark.hpc.test=value -Dspark.local.dir=/scr/8432301' as a work-around.
14/08/27 12:04:56 WARN SparkConf: Setting 'spark.driver.extraJavaOptions' to '-Dspark.hpc.test=value -Dspark.local.dir=/scr/8432301' as a work-around.
14/08/27 12:04:56 WARN SparkConf: 
SPARK_CLASSPATH was detected (set to '/home/szu004/dev/spark-hpc/examples/core/target/tests-core_2.10-1.0.jar:/home/szu004/dev/spark-hpc/examples/jni/target/tests-jni-1.0.jar:').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
14/08/27 12:04:56 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/szu004/dev/spark-hpc/examples/core/target/tests-core_2.10-1.0.jar:/home/szu004/dev/spark-hpc/examples/jni/target/tests-jni-1.0.jar:' as a work-around.
14/08/27 12:04:56 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/szu004/dev/spark-hpc/examples/core/target/tests-core_2.10-1.0.jar:/home/szu004/dev/spark-hpc/examples/jni/target/tests-jni-1.0.jar:' as a work-around.
14/08/27 12:04:56 INFO SecurityManager: Changing view acls to: szu004
14/08/27 12:04:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(szu004)
14/08/27 12:04:57 INFO Slf4jLogger: Slf4jLogger started
14/08/27 12:04:57 INFO Remoting: Starting remoting
14/08/27 12:04:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@n050.cluster:41100]
14/08/27 12:04:57 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@n050.cluster:41100]
14/08/27 12:04:57 INFO SparkEnv: Registering MapOutputTracker
14/08/27 12:04:57 INFO SparkEnv: Registering BlockManagerMaster
14/08/27 12:04:57 INFO DiskBlockManager: Created local directory at /scr/8432301/spark-local-20140827120457-0ef7
14/08/27 12:04:57 INFO MemoryStore: MemoryStore started with capacity 1177.6 MB.
14/08/27 12:04:57 INFO ConnectionManager: Bound socket to port 58397 with id = ConnectionManagerId(n050.cluster,58397)
14/08/27 12:04:57 INFO BlockManagerMaster: Trying to register BlockManager
14/08/27 12:04:57 INFO BlockManagerInfo: Registering block manager n050.cluster:58397 with 1177.6 MB RAM
14/08/27 12:04:57 INFO BlockManagerMaster: Registered BlockManager
14/08/27 12:04:57 INFO HttpServer: Starting HTTP Server
14/08/27 12:04:57 INFO HttpBroadcast: Broadcast server started at http://10.0.3.50:42215
14/08/27 12:04:57 INFO HttpFileServer: HTTP File server directory is /tmp/spark-5b0cd539-e1a7-4132-a007-8c600c693371
14/08/27 12:04:57 INFO HttpServer: Starting HTTP Server
14/08/27 12:04:58 INFO SparkUI: Started SparkUI at http://n050.cluster:4040
14/08/27 12:04:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/08/27 12:04:58 WARN SparkContext: Using SPARK_MEM to set amount of memory to use per executor process is deprecated, please use spark.executor.memory instead.
14/08/27 12:04:58 INFO SimrSchedulerBackend: Writing to HDFS file: /flush/szu004/.sparkhpc/job.8432301.bragg-l-mgt.cluster.n1GSbl/commfile
14/08/27 12:04:58 INFO SimrSchedulerBackend: Writing Akka address: akka.tcp://spark@n050.cluster:41100/user/CoarseGrainedScheduler
14/08/27 12:04:58 INFO SimrSchedulerBackend: Writing Spark UI Address: http://n050.cluster:4040
14/08/27 12:04:59 INFO MemoryStore: ensureFreeSpace(73060) called with curMem=0, maxMem=1234816204
14/08/27 12:04:59 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 71.3 KB, free 1177.5 MB)
14/08/27 12:04:59 INFO FileInputFormat: Total input paths to process : 1
14/08/27 12:04:59 INFO SparkContext: Starting job: toArray at JniTestEnv.scala:59
14/08/27 12:04:59 INFO DAGScheduler: Got job 0 (toArray at JniTestEnv.scala:59) with 2 output partitions (allowLocal=false)
14/08/27 12:04:59 INFO DAGScheduler: Final stage: Stage 0(toArray at JniTestEnv.scala:59)
14/08/27 12:04:59 INFO DAGScheduler: Parents of final stage: List()
14/08/27 12:04:59 INFO DAGScheduler: Missing parents: List()
14/08/27 12:04:59 INFO DAGScheduler: Submitting Stage 0 (MappedRDD[2] at map at JniTestEnv.scala:55), which has no missing parents
14/08/27 12:04:59 INFO DAGScheduler: Submitting 2 missing tasks from Stage 0 (MappedRDD[2] at map at JniTestEnv.scala:55)
14/08/27 12:04:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
Warning: SPARK_MEM is deprecated, please use a more specific config option
(e.g., spark.executor.memory or SPARK_DRIVER_MEMORY).
Spark assembly has been built with Hive, including Datanucleus jars on classpath
Picked up _JAVA_OPTIONS: -XX:ParallelGCThreads=1
log4j:WARN No appenders could be found for logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
14/08/27 12:05:01 INFO SparkHadoopUtil: Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
14/08/27 12:05:01 INFO SecurityManager: Changing view acls to: szu004
14/08/27 12:05:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(szu004)
14/08/27 12:05:02 INFO Slf4jLogger: Slf4jLogger started
14/08/27 12:05:02 INFO Remoting: Starting remoting
14/08/27 12:05:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkExecutor@n050:53651]
14/08/27 12:05:02 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkExecutor@n050:53651]
14/08/27 12:05:02 INFO CoarseGrainedExecutorBackend: Connecting to driver: akka.tcp://spark@n050.cluster:41100/user/CoarseGrainedScheduler
14/08/27 12:05:02 INFO SimrSchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@n050:53651/user/Executor#-1411367462] with ID executor-n050-13090-1
14/08/27 12:05:02 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor executor-n050-13090-1: n050 (PROCESS_LOCAL)
14/08/27 12:05:02 INFO TaskSetManager: Serialized task 0.0:0 as 1917 bytes in 9 ms
14/08/27 12:05:02 INFO TaskSetManager: Starting task 0.0:1 as TID 1 on executor executor-n050-13090-1: n050 (PROCESS_LOCAL)
14/08/27 12:05:02 INFO TaskSetManager: Serialized task 0.0:1 as 1917 bytes in 1 ms
14/08/27 12:05:02 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
14/08/27 12:05:02 INFO SecurityManager: Changing view acls to: szu004
14/08/27 12:05:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(szu004)
14/08/27 12:05:02 INFO Slf4jLogger: Slf4jLogger started
14/08/27 12:05:02 INFO Remoting: Starting remoting
14/08/27 12:05:02 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@n050:57846]
14/08/27 12:05:02 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@n050:57846]
14/08/27 12:05:02 INFO SparkEnv: Connecting to MapOutputTracker: akka.tcp://spark@n050.cluster:41100/user/MapOutputTracker
14/08/27 12:05:02 INFO SparkEnv: Connecting to BlockManagerMaster: akka.tcp://spark@n050.cluster:41100/user/BlockManagerMaster
14/08/27 12:05:02 INFO DiskBlockManager: Created local directory at /scr/8432301/spark-local-20140827120502-b945
14/08/27 12:05:02 INFO MemoryStore: MemoryStore started with capacity 1177.6 MB.
14/08/27 12:05:02 INFO ConnectionManager: Bound socket to port 40720 with id = ConnectionManagerId(n050,40720)
14/08/27 12:05:02 INFO BlockManagerMaster: Trying to register BlockManager
14/08/27 12:05:02 INFO BlockManagerInfo: Registering block manager n050:40720 with 1177.6 MB RAM
14/08/27 12:05:02 INFO BlockManagerMaster: Registered BlockManager
14/08/27 12:05:02 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ecdce378-2ec9-456d-924f-9e031609504e
14/08/27 12:05:02 INFO HttpServer: Starting HTTP Server
14/08/27 12:05:03 INFO CoarseGrainedExecutorBackend: Got assigned task 0
14/08/27 12:05:03 INFO CoarseGrainedExecutorBackend: Got assigned task 1
14/08/27 12:05:03 INFO Executor: Running task ID 0
14/08/27 12:05:03 INFO Executor: Running task ID 1
14/08/27 12:05:03 INFO HttpBroadcast: Started reading broadcast variable 0
14/08/27 12:05:03 INFO MemoryStore: ensureFreeSpace(295054) called with curMem=0, maxMem=1234816204
14/08/27 12:05:03 INFO MemoryStore: Block broadcast_0 stored as values to memory (estimated size 288.1 KB, free 1177.3 MB)
14/08/27 12:05:03 INFO HttpBroadcast: Reading broadcast variable 0 took 0.323943103 s
14/08/27 12:05:03 INFO BlockManager: Found block broadcast_0 locally
14/08/27 12:05:03 INFO HadoopRDD: Input split: file:/home/szu004/dev/spark-hpc/examples/data/lady_of_shalott.txt:0+587
14/08/27 12:05:03 INFO HadoopRDD: Input split: file:/home/szu004/dev/spark-hpc/examples/data/lady_of_shalott.txt:587+587
14/08/27 12:05:03 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
14/08/27 12:05:03 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
14/08/27 12:05:03 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
14/08/27 12:05:03 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
14/08/27 12:05:03 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
14/08/27 12:05:05 INFO Executor: Serialized size of result for 0 is 1185
14/08/27 12:05:05 INFO Executor: Sending result for 0 directly to driver
14/08/27 12:05:05 INFO Executor: Finished task ID 0
14/08/27 12:05:05 INFO DAGScheduler: Completed ResultTask(0, 0)
14/08/27 12:05:05 INFO TaskSetManager: Finished TID 0 in 3282 ms on n050 (progress: 1/2)
14/08/27 12:05:07 INFO Executor: Serialized size of result for 1 is 1182
14/08/27 12:05:07 INFO Executor: Sending result for 1 directly to driver
14/08/27 12:05:07 INFO Executor: Finished task ID 1
14/08/27 12:05:07 INFO DAGScheduler: Completed ResultTask(0, 1)
14/08/27 12:05:07 INFO TaskSetManager: Finished TID 1 in 4505 ms on n050 (progress: 2/2)
14/08/27 12:05:07 INFO DAGScheduler: Stage 0 (toArray at JniTestEnv.scala:59) finished in 7.727 s
14/08/27 12:05:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
14/08/27 12:05:07 INFO SparkContext: Job finished: toArray at JniTestEnv.scala:59, took 7.845420592 s
On either side the river lie
Long fields of barley and of rye,
That clothe the wold and meet the sky;
And thro' the field the road runs by
           To many-tower'd Camelot;
And up and down the people go,
Gazing where the lilies blow
Round an island there below,
           The island of Shalott.

Willows whiten, aspens quiver,
Little breezes dusk and shiver
Thro' the wave that runs for ever
By the island in the river
           Flowing down to Camelot.
Four gray walls, and four gray towers,
Overlook a space of flowers,
And the silent isle imbowers
           The Lady of Shalott.

By the margin, willow-veil'd
Slide the heavy barges trail'd
By slow horses; and unhail'd
The shallop flitteth silken-sail'd
           Skimming down to Camelot:
But who hath seen her wave her hand?
Or at the casement seen her stand?
Or is she known in all the land,
           The Lady of Shalott?

Only reapers, reaping early
In among the bearded barley,
Hear a song that echoes cheerly
From the river winding clearly,
           Down to tower'd Camelot:
And by the moon the reaper weary,
Piling sheaves in uplands airy,
Listening, whispers "'Tis the fairy
           Lady of Shalott."
14/08/27 12:05:07 ERROR CoarseGrainedExecutorBackend: Driver Disassociated [akka.tcp://sparkExecutor@n050:53651] -> [akka.tcp://spark@n050.cluster:41100] disassociated! Shutting down.
mpirun: killing job...

--------------------------------------------------------------------------
mpirun noticed that process rank 0 with PID 13090 on node n050 exited on signal 0 (Unknown signal 0).
--------------------------------------------------------------------------
mpirun: clean termination accomplished

removed directory: `/scr/8432301/openmpi-sessions-szu004@n050_0/15643'
removed directory: `/scr/8432301/openmpi-sessions-szu004@n050_0'
removed directory: `/scr/8432301'
removed directory: `/dev/shm/8432301'
Begin PBS Epilogue Wed Aug 27 12:05:08 EST 2014 1409105108
Job ID:              8432301.bragg-l-mgt.cluster
Username:            szu004
Group:               gpu-users
Name:                spark_jnitest_env
Session:             12895
Resources requested: neednodes=n050:ppn=2,nodes=2:ppn=1,vmem=6gb,walltime=00:00:30
Resources used:      cput=00:00:08,mem=2240156kb,vmem=2666052kb,walltime=00:00:14
Queue:               NORMAL
Account:             
Exit code:           0
End PBS Epilogue Wed Aug 27 12:05:08 EST 2014 1409105108
